{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitvscodeconda44b9c8763c6d447aa1b0e1f5ed6d1164",
   "display_name": "Python 3.8.1 64-bit ('vscode': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Resumption of the session Reprise de la session\n"
    }
   ],
   "source": [
    "#data is from European Parliament proceedings, download here: http://www.statmt.org/europarl/ \n",
    "PATH = '/home/tarushii/PythonNotebooks/Other_Projects/Transformer/data/' #set to the path to your data\n",
    "en_data = open(PATH + 'europarl-v7.fr-en.en', encoding='utf-8').read().split('\\n')\n",
    "fr_data = open(PATH + 'europarl-v7.fr-en.fr', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "print(en_data[0], fr_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch \n",
    "import torchtext\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_field = torchtext.data.Field(sequential=True, use_vocab=True, init_token='<sos>', eos_token='<eos>', tokenize='spacy', tokenizer_language='en')\n",
    "fr_field = torchtext.data.Field(sequential=True, use_vocab=True, init_token = '<sos>', eos_token = '<eos>', tokenize='spacy', tokenizer_language='fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, covert the data to a csv file to take advantage of torchtext's versatile TabularDataset class\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "raw_data = {'English' : [line for line in en_data], 'French': [line for line in fr_data]}\n",
    "df = pd.DataFrame(raw_data, columns=[\"English\", \"French\"])\n",
    "# create train and validation set \n",
    "train, val = train_test_split(df, test_size=0.1)\n",
    "train.to_csv(PATH + \"train.csv\", index=False)\n",
    "val.to_csv(PATH + \"val.csv\", index=False)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,val_set = torchtext.data.TabularDataset.splits(path=PATH, train='train.csv', validation='val.csv', format='csv', fields=[('English', en_field), ('French', fr_field)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": ".vector_cache/glove.6B.zip: 862MB [06:32, 2.20MB/s]\n100%|█████████▉| 398654/400000 [00:30<00:00, 21900.10it/s]"
    }
   ],
   "source": [
    "en_field.build_vocab(train_set, val_set, vectors='glove.6B.100d')\n",
    "fr_field.build_vocab(train_set, val_set, vectors='glove.6B.100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = torchtext.data.BucketIterator.splits((train_set, val_set), batch_size=2, sort_key=lambda x: len(x.French), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, embedding):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(embedding.shape[0], embedding.shape[1])\n",
    "        self.embed.weight.data.copy_(embedding)\n",
    "        self.embed.weight.requires_grad = False\n",
    "    def forward(self, input_sequence):\n",
    "        return self.embed(input_sequence)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, num_layers=1, dropout=0.0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = Embedder(embedding)\n",
    "        self.gru = nn.GRU(embedding.shape[1], hidden_size, num_layers=num_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
    "    def forward(self, input_sequence):\n",
    "        embedded = self.embedding(input_sequence) \n",
    "      #  x = nn.utils.rnn.pack_padded_sequence(x, lens) # unpad\n",
    "        outputs, hidden_state = self.gru(embedded) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
    "        # pad the sequence to the max length in the batch\n",
    "     #   output, _ = nn.utils.rnn.pad_packed_sequence(output)\n",
    "        # The ouput of a GRU has shape (seq_len, batch, hidden_size * num_directions)\n",
    "        # Because the Encoder is bidirectional, combine the results from the \n",
    "        # forward and reversed sequence by simply adding them together.\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        return outputs, hidden_state\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, batch_size, hidden_size, embedding, num_layers=1, drop_prob=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding.shape[1]\n",
    "        self.embedding = Embedder(embedding)\n",
    "        self.attn = nn.Linear(hidden_size * 2, 1)\n",
    "        self.gru = nn.GRU(embedding.shape[1]+hidden_size, hidden_size, num_layers=num_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_size, embedding.shape[0])\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs, inputs):\n",
    "        # Embed input words\n",
    "        embedded = self.embedding(inputs)\n",
    "        #Assumed size of decoder_hidden -> (num_layers, batch_size, embedding_size) size of encoder_outputs -> (batch_size, sentence_len, embedding_size)\n",
    "        #need to convert length of decoder_hidden to (batch_size, sentence_len, embedding_size)\n",
    "        self.sequence_len = encoder_outputs.shape[1]\n",
    "        decoder_hidden = torch.sum(decoder_hidden, axis=0)\n",
    "        attn_inp = decoder_hidden.unsqueeze(1).repeat(1, self.sequence_len,1)\n",
    "        weights = self.attn(torch.cat((attn_inp, encoder_outputs), dim = 2)).squeeze()\n",
    "        normalized_weights = F.softmax(weights)\n",
    "        attn_applied = torch.bmm(normalized_weights.unsqueeze(1), encoder_outputs).sqeeze()\n",
    "        cat_input = torch.cat((embedded, attn_applied), axis=2)\n",
    "        output, hidden_state = self.gru(cat_input, decoder_hidden.unsqueeze(0))\n",
    "        output = self.classifier(output).squeeze()\n",
    "        return output, hidden_state\n",
    "  \n",
    "def train(encoder, decoder, encoder_opt, decoder_opt, criterion, input, target):\n",
    "    #set both to train moode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    #pass through encoder\n",
    "    enc_output, enc_hidden = encoder(target)\n",
    "    #initialize input to '<sos>' tokends anddecoder hidden state to final encoder hidden state\n",
    "    dec_input, dec_hidden = target[:, 0].unsqueeze(1), enc_hidden\n",
    "    loss = 0\n",
    "    for i in range(1, target.shape[1]):\n",
    "        dec_input, dec_hidden = decoder(dec_hidden, enc_output, dec_input)\n",
    "        loss += criterion(dec_input, target[:, i])\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        dec_input = topi.squeeze().detach()  # detach from history as input\n",
    "    loss.backward()\n",
    "    encoder_opt.step()\n",
    "    decoder_opt.step()\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 200\n",
    "batch_size = 2\n",
    "epochs = 1\n",
    "encoder = Encoder(hidden_size, en_field.vocab.vectors)#.to(device)\n",
    "decoder = Decoder(batch_size, hidden_size, fr_field.vocab.vectors)#.to(device)\n",
    "encoder_opt = torch.optim.Adam([param for param in encoder.parameters() if param.requires_grad == True], lr=1.0e-4)\n",
    "decoder_opt = torch.optim.Adam([param for param in decoder.parameters() if param.requires_grad == True], lr=1.0e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "source": [
    "it = iter(train_iter)\n",
    "batch = next(it)\n",
    "#set both to train moode\n",
    "#encoder.train()\n",
    "#decoder.train()\n",
    "#pass through encoder\n",
    "input = batch.English.t()#.to(device)\n",
    "target = batch.French.t()#.to(device)\n",
    "enc_output, enc_hidden = encoder(target)\n",
    "#initialize input to '<sos>' tokends anddecoder hidden state to final encoder hidden state\n",
    "dec_input, dec_hidden = target[:, 0].unsqueeze(1), enc_hidden\n",
    "loss = 0\n",
    "for i in range(1, target.shape[1]):\n",
    "    dec_input, dec_hidden = decoder(dec_hidden, enc_output, dec_input)\n",
    "    loss += criterion(dec_input, target[:, i])\n",
    "    topv, topi = dec_input.topk(1)\n",
    "    dec_input = topi.squeeze().detach()  # detach from history as input\n",
    "loss.backward()\n",
    "encoder_opt.step()\n",
    "decoder_opt.step()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "for i in range(epochs):\n",
    "    losses = []\n",
    "    print('Epoch %x:' % i, end='')\n",
    "    c = 0\n",
    "    for batch in train_iter:\n",
    "        input = batch.English.t().to(device)\n",
    "        target = batch.French.t().to(device)\n",
    "        losses.append(train(encoder, decoder, encoder_opt, decoder_opt, criterion, input, target))\n",
    "        if (c % 10 == 0):\n",
    "            print('.', end='')\n",
    "        c+=1\n",
    "    print(' loss: ', sum(losses)/len(losses))\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
